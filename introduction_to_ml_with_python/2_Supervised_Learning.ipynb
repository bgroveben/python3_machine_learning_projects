{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) is used when we want to predict a certain outcome from a given input, and we have examples of input/output pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two major types of supervised machine learning problems, called [classification](https://en.wikipedia.org/wiki/Statistical_classification) and [regression](https://en.wikipedia.org/wiki/Regression_analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification, the goal is to predit a *class label*, which is a choice from a predefined list of possibilities.  \n",
    "In chapter 1 we used the example of classifying irises into one of three possible species.  \n",
    "Classification is sometimes separated into *binary classification*, which is the special case of distinguishing between exactly two classes, and *multiclass classification*, which is classification between more than two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression tasks, the goal is to predict a continuous number, a floating-point number, or a real number.  \n",
    "Predicting a person's annual income from their education, their age, and where they live is an example of a regression task.  \n",
    "When predicting income, the predicted value is an amount and can be any number in a given range.  \n",
    "Another example of a regression task is predicting the yield of a corn farm given attributes such as previous yields, weather, and number of employees working on the farm.  \n",
    "The yield again can be an arbitrary number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy way to distinguish between classification and regression tasks is to ask whether there is some kind of continuity in the output.  \n",
    "If there is continuity between possible outcomes, then the problem is a regression problem.  \n",
    "Think about predicting annual income -- there is clear continuity in the output.  \n",
    "Whether a person makes $50,000 or $50,001 per year doesn't make much difference, even though they are technically different dollar amounts.  \n",
    "By contrast, recognizing which language a book is written in is a classification problem because there is no matter of degree.  \n",
    "The book is written in English, or Arabic, or French, or some other language; there is no continuity between languages and there is no language that is *between* Arabic and French."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization, Overfitting, and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We want to build a model that is able to generalize as accurately as possible.  \n",
    "Building a model that is too complex for the amount of information available is called [overfitting](https://en.wikipedia.org/wiki/Overfitting).  \n",
    "Overfitting occurs when you fit a model too closely to the particularities of the training set and come up with a model that works well on that training set but is not able to generalize to new data.  \n",
    "On the other hand, if your model is too simple or whose scope is too broadly defined, then you might not be able to capture all the aspects of and variability in the data.  \n",
    "This is known as [underfitting](https://en.wikipedia.org/wiki/Overfitting#Underfitting), and will result in your model performing poorly on both the training and test sets because it cannot capture the underlying trend of the data.  \n",
    "You can learn more about underfitting vs. overfitting [in the scikit-learn documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation of Model Complexity to Dataset Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that model complexity is initmately tied to the variation of inputs contained in your training dataset.  \n",
    "The larger the variety of data points that your dataset contains, the more complex a model you can use without overfitting.  \n",
    "Usually, collecting more data points will yield more variety, so larger datasets allow you to build more complex models.  \n",
    "In the real world, you often have the ability to decide how much data to collect, which might be more beneficial than tweaking and tuning your model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the fun begins.  \n",
    "We will now review the most popular machine learning algorithms and explain how they learn from data and how they make predictions.  \n",
    "This chapter can be used as a reference guide for the rest of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Sample Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using several different datasets to illustrate the various algorithms.  \n",
    "Many of the algorithms will have a classification and a regression variant, and we will describe both.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a synthetic (made-up) two-class (binary) classification dataset is the `forge` dataset from the `mglearn` module.  \n",
    "The following code creates a scatter plot visualizing all of the data points in the dataset.  \n",
    "The plot has the first (of two) feature on the x-axis and the second feature on the y-axis.  \n",
    "Each data point is represented as one dot, and the color and shape of the dot indicates its class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[  9.96346605   4.59676542]\n",
      " [ 11.0329545   -0.16816717]\n",
      " [ 11.54155807   5.21116083]\n",
      " [  8.69289001   1.54322016]\n",
      " [  8.1062269    4.28695977]\n",
      " [  8.30988863   4.80623966]\n",
      " [ 11.93027136   4.64866327]\n",
      " [  9.67284681  -0.20283165]\n",
      " [  8.34810316   5.13415623]\n",
      " [  8.67494727   4.47573059]\n",
      " [  9.17748385   5.09283177]\n",
      " [ 10.24028948   2.45544401]\n",
      " [  8.68937095   1.48709629]\n",
      " [  8.92229526  -0.63993225]\n",
      " [  9.49123469   4.33224792]\n",
      " [  9.25694192   5.13284858]\n",
      " [  7.99815287   4.8525051 ]\n",
      " [  8.18378052   1.29564214]\n",
      " [  8.7337095    2.49162431]\n",
      " [  9.32298256   5.09840649]\n",
      " [ 10.06393839   0.99078055]\n",
      " [  9.50048972  -0.26430318]\n",
      " [  8.34468785   1.63824349]\n",
      " [  9.50169345   1.93824624]\n",
      " [  9.15072323   5.49832246]\n",
      " [ 11.563957     1.3389402 ]]\n",
      "y:\n",
      "[1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "print(\"X:\")\n",
    "print(X)\n",
    "print(\"y:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: \n",
      "(26, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118cf8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot dataset\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.legend([\"Class 0\", \"Class 1\"], loc=4)\n",
    "plt.xlabel(\"First Feature\")\n",
    "plt.ylabel(\"Second Feature\")\n",
    "print(\"X.shape: \\n{}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from `X.shape`, this dataset consists of 26 data points, with 2 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate regression algorithms, we will use the `synthetic wave` dataset from the `mglearn` module.  \n",
    "The `wave` dataset has a single input feature and a continuous target variable (or *response*) that we want to model.  \n",
    "The plot created below shows the single feature on the x-axis and the regression target (the output) on the y-axis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[-0.75275929]\n",
      " [ 2.70428584]\n",
      " [ 1.39196365]\n",
      " [ 0.59195091]\n",
      " [-2.06388816]\n",
      " [-2.06403288]\n",
      " [-2.65149833]\n",
      " [ 2.19705687]\n",
      " [ 0.60669007]\n",
      " [ 1.24843547]\n",
      " [-2.87649303]\n",
      " [ 2.81945911]\n",
      " [ 1.99465584]\n",
      " [-1.72596534]\n",
      " [-1.9090502 ]\n",
      " [-1.89957294]\n",
      " [-1.17454654]\n",
      " [ 0.14853859]\n",
      " [-0.40832989]\n",
      " [-1.25262516]\n",
      " [ 0.67111737]\n",
      " [-2.16303684]\n",
      " [-1.24713211]\n",
      " [-0.80182894]\n",
      " [-0.26358009]\n",
      " [ 1.71105577]\n",
      " [-1.80195731]\n",
      " [ 0.08540663]\n",
      " [ 0.55448741]\n",
      " [-2.72129752]\n",
      " [ 0.64526911]\n",
      " [-1.97685526]\n",
      " [-2.60969044]\n",
      " [ 2.69331322]\n",
      " [ 2.7937922 ]\n",
      " [ 1.85038409]\n",
      " [-1.17231738]\n",
      " [-2.41396732]\n",
      " [ 1.10539816]\n",
      " [-0.35908504]]\n",
      "y:\n",
      "[-0.44822073  0.33122576  0.77932073  0.03497884 -1.38773632 -2.47196233\n",
      " -1.52730805  1.49417157  1.00032374  0.22956153 -1.05979555  0.7789638\n",
      "  0.75418806 -1.51369739 -1.67303415 -0.90496988  0.08448544 -0.52734666\n",
      " -0.54114599 -0.3409073   0.21778193 -1.12469096  0.37299129  0.09756349\n",
      " -0.98618122  0.96695428 -1.13455014  0.69798591  0.43655826 -0.95652133\n",
      "  0.03527881 -2.08581717 -0.47411033  1.53708251  0.86893293  1.87664889\n",
      "  0.0945257  -1.41502356  0.25438895  0.09398858]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x118cc7400>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118c80630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "print(\"X:\")\n",
    "print(X)\n",
    "print(\"y:\")\n",
    "print(y)\n",
    "plt.plot(X, y, 'o')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using these very simple, low-dimensional datasets because we can easily visualize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will complement these small synthetic datasets with two real-world datasets that are included in `scikit-learn`.  \n",
    "One is the [Wisconsin Breast Cancer dataset](http://scikit-learn.org/stable/datasets/index.html#breast-cancer-wisconsin-diagnostic-database) (aka `cancer`), which records clinical measurements of breast cancer tumors.  \n",
    "Each tumor is labeled as \"benign\" or \"malignant\", and the task is to learn to predict whether a tumor is malignant based on the measurements of the tissue.  \n",
    "The data can be loaded using the `load_breast_cancer` function from `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys(): \n",
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys(): \\n{}\".format(cancer.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Breast Cancer Wisconsin (Diagnostic) Database\\n=============================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\nReferences\\n----------\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.\\n',\n",
       " 'data': array([[  1.79900000e+01,   1.03800000e+01,   1.22800000e+02, ...,\n",
       "           2.65400000e-01,   4.60100000e-01,   1.18900000e-01],\n",
       "        [  2.05700000e+01,   1.77700000e+01,   1.32900000e+02, ...,\n",
       "           1.86000000e-01,   2.75000000e-01,   8.90200000e-02],\n",
       "        [  1.96900000e+01,   2.12500000e+01,   1.30000000e+02, ...,\n",
       "           2.43000000e-01,   3.61300000e-01,   8.75800000e-02],\n",
       "        ..., \n",
       "        [  1.66000000e+01,   2.80800000e+01,   1.08300000e+02, ...,\n",
       "           1.41800000e-01,   2.21800000e-01,   7.82000000e-02],\n",
       "        [  2.06000000e+01,   2.93300000e+01,   1.40100000e+02, ...,\n",
       "           2.65000000e-01,   4.08700000e-01,   1.24000000e-01],\n",
       "        [  7.76000000e+00,   2.45400000e+01,   4.79200000e+01, ...,\n",
       "           0.00000000e+00,   2.87100000e-01,   7.03900000e-02]]),\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "        'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "        'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "        'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
       "       dtype='<U23'),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'],\n",
       "       dtype='<U9')}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "Datasets that are included in `scikit-learn` are usually stored as [Bunch objects](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/base.py), which contain some information about the dataset as well as the actual data.  \n",
    "The most important thing to know about `Bunch` objects is that they behave like Python dictionaries, with the added benefit of accessing values using a dot (as in `bunch.key` instead of `bunch['key']`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 569 data points, with 30 features each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cancer data: \n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of cancer data: \\n{}\".format(cancer.data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these 569 data points, 212 are labeled as malignant and 357 as benign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts per class: \n",
      "{'malignant': 212, 'benign': 357}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample counts per class: \\n{}\".format(\n",
    "    {n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a description of the semantic meaning of each feature, we can have a look at the `feature_names` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: \n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature names: \\n{}\".format(cancer.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find out more about the data by reading `cancer.DESCR` if you are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be using a real-world regression dataset, the [Boston Housing dataset](http://scikit-learn.org/stable/datasets/index.html#boston-house-prices-dataset).  \n",
    "The task associated with this dataset is to predict the median value of homes in several Boston neighborhoods in the 1970's by using information such as crime rate, proximity to the Charles River, highway accessibility, and so on.  \n",
    "The dataset contains 506 data points which are described by 13 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: \n",
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(\"Data shape: \\n{}\".format(boston.data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes here, we will actually expand this dataset by not only considering these 13 measurements as input features, but also looking at all products (also called *interactions*) between features.  \n",
    "In other words, we will not only consider crime rate and highway accessibility as features, but also the product of crime rate and highway accessibility.  \n",
    "Including derived features like these is called [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering), which will be discussed in more detail in Chapter 4.  \n",
    "This derived dataset can be loaded using the `load_extended_boston` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[  0.00000000e+00   1.80000000e-01   6.78152493e-02 ...,   1.00000000e+00\n",
      "    8.96799117e-02   8.04248656e-03]\n",
      " [  2.35922539e-04   0.00000000e+00   2.42302053e-01 ...,   1.00000000e+00\n",
      "    2.04470199e-01   4.18080621e-02]\n",
      " [  2.35697744e-04   0.00000000e+00   2.42302053e-01 ...,   9.79579831e-01\n",
      "    6.28144504e-02   4.02790570e-03]\n",
      " ..., \n",
      " [  6.11892474e-04   0.00000000e+00   4.20454545e-01 ...,   1.00000000e+00\n",
      "    1.07891832e-01   1.16406475e-02]\n",
      " [  1.16072990e-03   0.00000000e+00   4.20454545e-01 ...,   9.82676920e-01\n",
      "    1.29930407e-01   1.71795127e-02]\n",
      " [  4.61841693e-04   0.00000000e+00   4.20454545e-01 ...,   1.00000000e+00\n",
      "    1.69701987e-01   2.87987643e-02]]\n",
      "y:\n",
      "[ 24.   21.6  34.7  33.4  36.2  28.7  22.9  27.1  16.5  18.9  15.   18.9\n",
      "  21.7  20.4  18.2  19.9  23.1  17.5  20.2  18.2  13.6  19.6  15.2  14.5\n",
      "  15.6  13.9  16.6  14.8  18.4  21.   12.7  14.5  13.2  13.1  13.5  18.9\n",
      "  20.   21.   24.7  30.8  34.9  26.6  25.3  24.7  21.2  19.3  20.   16.6\n",
      "  14.4  19.4  19.7  20.5  25.   23.4  18.9  35.4  24.7  31.6  23.3  19.6\n",
      "  18.7  16.   22.2  25.   33.   23.5  19.4  22.   17.4  20.9  24.2  21.7\n",
      "  22.8  23.4  24.1  21.4  20.   20.8  21.2  20.3  28.   23.9  24.8  22.9\n",
      "  23.9  26.6  22.5  22.2  23.6  28.7  22.6  22.   22.9  25.   20.6  28.4\n",
      "  21.4  38.7  43.8  33.2  27.5  26.5  18.6  19.3  20.1  19.5  19.5  20.4\n",
      "  19.8  19.4  21.7  22.8  18.8  18.7  18.5  18.3  21.2  19.2  20.4  19.3\n",
      "  22.   20.3  20.5  17.3  18.8  21.4  15.7  16.2  18.   14.3  19.2  19.6\n",
      "  23.   18.4  15.6  18.1  17.4  17.1  13.3  17.8  14.   14.4  13.4  15.6\n",
      "  11.8  13.8  15.6  14.6  17.8  15.4  21.5  19.6  15.3  19.4  17.   15.6\n",
      "  13.1  41.3  24.3  23.3  27.   50.   50.   50.   22.7  25.   50.   23.8\n",
      "  23.8  22.3  17.4  19.1  23.1  23.6  22.6  29.4  23.2  24.6  29.9  37.2\n",
      "  39.8  36.2  37.9  32.5  26.4  29.6  50.   32.   29.8  34.9  37.   30.5\n",
      "  36.4  31.1  29.1  50.   33.3  30.3  34.6  34.9  32.9  24.1  42.3  48.5\n",
      "  50.   22.6  24.4  22.5  24.4  20.   21.7  19.3  22.4  28.1  23.7  25.\n",
      "  23.3  28.7  21.5  23.   26.7  21.7  27.5  30.1  44.8  50.   37.6  31.6\n",
      "  46.7  31.5  24.3  31.7  41.7  48.3  29.   24.   25.1  31.5  23.7  23.3\n",
      "  22.   20.1  22.2  23.7  17.6  18.5  24.3  20.5  24.5  26.2  24.4  24.8\n",
      "  29.6  42.8  21.9  20.9  44.   50.   36.   30.1  33.8  43.1  48.8  31.\n",
      "  36.5  22.8  30.7  50.   43.5  20.7  21.1  25.2  24.4  35.2  32.4  32.\n",
      "  33.2  33.1  29.1  35.1  45.4  35.4  46.   50.   32.2  22.   20.1  23.2\n",
      "  22.3  24.8  28.5  37.3  27.9  23.9  21.7  28.6  27.1  20.3  22.5  29.\n",
      "  24.8  22.   26.4  33.1  36.1  28.4  33.4  28.2  22.8  20.3  16.1  22.1\n",
      "  19.4  21.6  23.8  16.2  17.8  19.8  23.1  21.   23.8  23.1  20.4  18.5\n",
      "  25.   24.6  23.   22.2  19.3  22.6  19.8  17.1  19.4  22.2  20.7  21.1\n",
      "  19.5  18.5  20.6  19.   18.7  32.7  16.5  23.9  31.2  17.5  17.2  23.1\n",
      "  24.5  26.6  22.9  24.1  18.6  30.1  18.2  20.6  17.8  21.7  22.7  22.6\n",
      "  25.   19.9  20.8  16.8  21.9  27.5  21.9  23.1  50.   50.   50.   50.\n",
      "  50.   13.8  13.8  15.   13.9  13.3  13.1  10.2  10.4  10.9  11.3  12.3\n",
      "   8.8   7.2  10.5   7.4  10.2  11.5  15.1  23.2   9.7  13.8  12.7  13.1\n",
      "  12.5   8.5   5.    6.3   5.6   7.2  12.1   8.3   8.5   5.   11.9  27.9\n",
      "  17.2  27.5  15.   17.2  17.9  16.3   7.    7.2   7.5  10.4   8.8   8.4\n",
      "  16.7  14.2  20.8  13.4  11.7   8.3  10.2  10.9  11.    9.5  14.5  14.1\n",
      "  16.1  14.3  11.7  13.4   9.6   8.7   8.4  12.8  10.5  17.1  18.4  15.4\n",
      "  10.8  11.8  14.9  12.6  14.1  13.   13.4  15.2  16.1  17.8  14.9  14.1\n",
      "  12.7  13.5  14.9  20.   16.4  17.7  19.5  20.2  21.4  19.9  19.   19.1\n",
      "  19.1  20.1  19.9  19.6  23.2  29.8  13.8  13.3  16.7  12.   14.6  21.4\n",
      "  23.   23.7  25.   21.8  20.6  21.2  19.1  20.6  15.2   7.    8.1  13.6\n",
      "  20.1  21.8  24.5  23.1  19.7  18.3  21.2  17.5  16.8  22.4  20.6  23.9\n",
      "  22.   11.9]\n",
      "X.shape: \n",
      "(506, 104)\n"
     ]
    }
   ],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "print(\"X:\")\n",
    "print(X)\n",
    "print(\"y:\")\n",
    "print(y)\n",
    "print(\"X.shape: \\n{}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting 104 features are the 13 original features together with the 91 possible combinations of two features within those 13.  \n",
    "We will use the above datasets to explain and illustrate the properties of the different machine learning algorithms.  \n",
    "But for now, let's get to the algorithms themselves.  \n",
    "First, we'll revisit the `k`-nearest neighbors (KNN) algorithm that we saw in the previous chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
