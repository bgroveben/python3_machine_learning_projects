{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. Representing Data and Engineering Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we’ve assumed that our data comes in as a two-dimensional array of floating-point numbers, where each column is a [continuous feature](https://www.mathsisfun.com/data/data-discrete-continuous.html) that describes the data points.  \n",
    "For many applications, this is not how the data is collected.  \n",
    "A particularly common type of feature is the [categorical features](http://www.dummies.com/education/math/statistics/types-of-statistical-data-numerical-categorical-and-ordinal/).  \n",
    "Also known as [discrete features](https://www.mathsisfun.com/data/data-discrete-continuous.html), these are usually not numeric.  \n",
    "The distinction between categorical features and continuous features is analogous to the distinction between classification and regression, only on the input side rather than the output side.  \n",
    "Examples of continuous features that we have seen are pixel brightnesses and size measurements of plant flowers.  \n",
    "Examples of categorical features are the brand of a product, the color of a product, or the department (books, clothing, hardware) it is sold in.  \n",
    "These are all properties that can describe a product, but they don’t vary in a continuous way.  \n",
    "A product belongs either in the clothing department or in the books department.  \n",
    "There is no middle ground between books and clothing, and no natural order for the different categories (books is not greater or less than clothing, hardware is not between books and clothing, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the types of features your data consists of, how you represent them can have an enormous effect on the performance of machine learning models.  \n",
    "We saw in Chapters 2 and 3 that scaling of the data is important.  \n",
    "In other words, if you don’t rescale your data (say, to unit variance), then it makes a difference whether you represent a measurement in centimeters or inches.  \n",
    "We also saw in Chapter 2 that it can be helpful to *augment* your data with additional features, like adding interactions (products) of features or more general polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question of how to represent your data best for a particular application is known as feature engineering, and it is one of the main tasks of data scientists and machine learning practitioners trying to solve real-world problems.  \n",
    "Representing your data in the right way can have a bigger influence on the performance of a supervised model than the exact parameters you choose.  \n",
    "In this chapter, we will first go over the important and very common case of categorical features, and then give some examples of helpful transformations for specific combinations of features and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we will use the dataset of adult incomes in the United States, derived from the 1994 census database.  \n",
    "The task of the adult dataset is to predict whether a worker has an income of over \\$50,000 or under \\$50,000.  \n",
    "The features in this dataset include the workers’ ages, how they are employed (self employed, private industry employee, government employee, etc.), their education, their gender, their working hours per week, occupation, and more.  \n",
    "Table 4-1 shows the first few entries in the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/adult_incomes_data.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Table 4-1. The first few entries in the adult employment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is phrased as a classification task with the two classes being income `<=50k` and `>50k`.  \n",
    "It would also be possible to predict the exact income, and make this a regression task.  \n",
    "However, that would be much more difficult, and the 50K division is interesting to understand on its own.  \n",
    "In this dataset, `age` and `hours-per-week` are continuous features, which we know how to treat.  \n",
    "The `workclass`, `education`, `sex`, and `occupation` features are categorical, however.  \n",
    "All of them come from a fixed list of possible values, as opposed to a range, and denote a qualitative property, as opposed to a quantity.  \n",
    "As a starting point, let’s say we want to learn a logistic regression classifier on this data.  \n",
    "We know from Chapter 2 that a logistic regression makes predictions, $ŷ$, using the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ŷ = w[0] * x[0] +w[1] * x[1] + \\ldots + w[p] * x[p] + b > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $w[i]$ and $b$ are coefficients learned from the training set and $x[i]$ are the input features.  \n",
    "This formula makes sense when $x[i]$ are numbers, but not when $x[2]$ is `\"Masters\"` or `\"Bachelors\"`.  \n",
    "Clearly we need to represent our data in some different way when applying logistic regression.  \n",
    "The next section will explain how we can overcome this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding (Dummy Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By far the most common way to represent categorical variables is using the [one-hot-encoding](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science) or *one-out-of-N encoding*, also known as [dummy variables](https://en.wikipedia.org/wiki/Dummy_variable_%28statistics%29).  \n",
    "The idea behind dummy variables is to replace a categorical variable with one or more new features that can have the values 0 and 1.  \n",
    "The values 0 and 1 make sense in the formula for linear binary classification (and for all other models in `scikit-learn`), and we can represent any number of categories by introducing one new feature per category, as described here.  \n",
    "Let’s say for the workclass feature we have possible values of `\"Government Employee\"`, `\"Private Employee\"`, `\"Self Employed\"`, and `\"Self Employed Incorporated\"`.  \n",
    "To encode these four possible values, we create four new features, called `\"Government Employee\"`, `\"Private Employee\"`, `\"Self Employed\"`, and `\"Self Employed Incorporated\"`.  \n",
    "A feature is 1 if `workclass` for this person has the corresponding value and 0 otherwise, so exactly one of the four new features will be 1 for each data point.  \n",
    "This is why this is called *one-hot* or *one-out-of-N* encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principle is illustrated in Table 4-2.  \n",
    "A single feature is encoded using four new features.  \n",
    "When using this data in a machine learning algorithm, we would drop the original `workclass` feature and only keep the 0-1 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/Table_4-2.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Table 4-2. Encoding the workclass feature using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**  \n",
    "The one-hot encoding we use is quite similar, but not identical, to the dummy coding used in statistics.  \n",
    "For simplicity, we encode each category with a different binary feature.  \n",
    "In statistics, it is common to encode a categorical feature with k different possible values into k–1 features (the last one is represented as all zeros).  \n",
    "This is done to simplify the analysis (more technically, this will avoid making the data matrix rank-deficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to convert your data to a one-hot encoding of categorical variables, using either [pandas](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) or [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).  \n",
    "At the time of writing, using pandas is slightly easier, so let’s go this route.  \n",
    "First we load the data using pandas from a comma-separated values (CSV) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/benjamingrove/.pyenv/versions/3.6.1/lib/python3.6/site-packages/mglearn/data/adult.data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# The file has no headers naking the columns, so we pass \n",
    "# header=None and provide the column names explicitly in \"names\".\n",
    "adult_path = os.path.join(mglearn.datasets.DATA_PATH, \"adult.data\")\n",
    "print(adult_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education   gender  hours-per-week  \\\n",
       "0   39          State-gov   Bachelors     Male              40   \n",
       "1   50   Self-emp-not-inc   Bachelors     Male              13   \n",
       "2   38            Private     HS-grad     Male              40   \n",
       "3   53            Private        11th     Male              40   \n",
       "4   28            Private   Bachelors   Female              40   \n",
       "\n",
       "           occupation  income  \n",
       "0        Adm-clerical   <=50K  \n",
       "1     Exec-managerial   <=50K  \n",
       "2   Handlers-cleaners   <=50K  \n",
       "3   Handlers-cleaners   <=50K  \n",
       "4      Prof-specialty   <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(adult_path, header=None, index_col=False,\n",
    "       names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "              'education-num', 'marital-status', 'occupation',\n",
    "              'relationship', 'race', 'gender', 'capital-gain',\n",
    "              'capital-loss', 'hours-per-week', 'native-country',\n",
    "              'income'])\n",
    "# For illustrative purposes, we'll only select some of the columns:\n",
    "data = data[['age', 'workclass', 'education', 'gender',\n",
    "             'hours-per-week', 'occupation', 'income']]\n",
    "# IPython.display allows nice output formatting within the \n",
    "# Jupyter notebook:\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Table 4-3. The first five rows of the adult employment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking string-encoded categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
