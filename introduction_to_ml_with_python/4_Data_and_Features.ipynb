{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. Representing Data and Engineering Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we’ve assumed that our data comes in as a two-dimensional array of floating-point numbers, where each column is a [continuous feature](https://www.mathsisfun.com/data/data-discrete-continuous.html) that describes the data points.  \n",
    "For many applications, this is not how the data is collected.  \n",
    "A particularly common type of feature is the *categorical features*.  \n",
    "Also known as [discrete features](https://www.mathsisfun.com/data/data-discrete-continuous.html), these are usually not numeric.  \n",
    "The distinction between categorical features and continuous features is analogous to the distinction between classification and regression, only on the input side rather than the output side.  \n",
    "Examples of continuous features that we have seen are pixel brightnesses and size measurements of plant flowers.  \n",
    "Examples of categorical features are the brand of a product, the color of a product, or the department (books, clothing, hardware) it is sold in.  \n",
    "These are all properties that can describe a product, but they don’t vary in a continuous way.  \n",
    "A product belongs either in the clothing department or in the books department.  \n",
    "There is no middle ground between books and clothing, and no natural order for the different categories (books is not greater or less than clothing, hardware is not between books and clothing, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the types of features your data consists of, how you represent them can have an enormous effect on the performance of machine learning models.  \n",
    "We saw in Chapters 2 and 3 that scaling of the data is important.  \n",
    "In other words, if you don’t rescale your data (say, to unit variance), then it makes a difference whether you represent a measurement in centimeters or inches.  \n",
    "We also saw in Chapter 2 that it can be helpful to *augment* your data with additional features, like adding interactions (products) of features or more general polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question of how to represent your data best for a particular application is known as feature engineering, and it is one of the main tasks of data scientists and machine learning practitioners trying to solve real-world problems.  \n",
    "Representing your data in the right way can have a bigger influence on the performance of a supervised model than the exact parameters you choose.  \n",
    "In this chapter, we will first go over the important and very common case of categorical features, and then give some examples of helpful transformations for specific combinations of features and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we will use the dataset of adult incomes in the United States, derived from the 1994 census database.  \n",
    "The task of the adult dataset is to predict whether a worker has an income of over \\$50,000 or under \\$50,000.  \n",
    "The features in this dataset include the workers’ ages, how they are employed (self employed, private industry employee, government employee, etc.), their education, their gender, their working hours per week, occupation, and more.  \n",
    "Table 4-1 shows the first few entries in the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/adult_incomes_data.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Table 4-1. The first few entries in the adult employment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is phrased as a classification task with the two classes being income `<=50k` and `>50k`.  \n",
    "It would also be possible to predict the exact income, and make this a regression task.  \n",
    "However, that would be much more difficult, and the 50K division is interesting to understand on its own.  \n",
    "In this dataset, `age` and `hours-per-week` are continuous features, which we know how to treat.  \n",
    "The `workclass`, `education`, `sex`, and `occupation` features are categorical, however.  \n",
    "All of them come from a fixed list of possible values, as opposed to a range, and denote a qualitative property, as opposed to a quantity.  \n",
    "As a starting point, let’s say we want to learn a logistic regression classifier on this data.  \n",
    "We know from Chapter 2 that a logistic regression makes predictions, $ŷ$, using the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ŷ = w[0] * x[0] +w[1] * x[1] + \\ldots + w[p] * x[p] + b > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $w[i]$ and $b$ are coefficients learned from the training set and $x[i]$ are the input features.  \n",
    "This formula makes sense when $x[i]$ are numbers, but not when $x[2]$ is `\"Masters\"` or `\"Bachelors\"`.  \n",
    "Clearly we need to represent our data in some different way when applying logistic regression.  \n",
    "The next section will explain how we can overcome this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding (Dummy Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
