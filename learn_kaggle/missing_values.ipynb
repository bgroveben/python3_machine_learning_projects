{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways data can end up with missing values.    \n",
    "* A 2 bedroom house doesn't have value for a third bedroom.\n",
    "* Someone being surveyed may choose not to share their income.\n",
    "\n",
    "Python libraries represent missing numbers as `nan` which is short for \"not a number\".  \n",
    "You can detect which cells have missing values, and then count how many there are in each column with the command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most libraries (including scikit-learn) will give you an error if you try to build a model using data with missing values.  \n",
    "Let's figure out how to deal with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. You can drop columns with missing values:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_without_missing_values = original_data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to drop the same columns from the DataFrames in both your training dataset and test dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols_with_missing_vals = [col for col in original_data.columns\n",
    "                                      if original_data[col].isnull().any()]\n",
    "reduced_original_data = original_data.drop(cols_with_missing, axis=1)\n",
    "reduced_test_data = test_data.drop(cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method discards all information in the entire column, so it can be useful when most values in a column are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. You can impute missing values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation replaces the missing value with some number (the mean, for example), which usually gives more accurate models than dropping the column entirely."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "my_imputer = Imputer()\n",
    "data_with_imputed_values = my_imputer.fit_transform(original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation can also be included in a scikit-learn Pipeline, which simplify model building, validation, and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. You can extend imputation to consider which values were originally missing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation is the standard approach, and it usually works well.  \n",
    "However, imputed values may by systematically above or below their actual values (which weren't collected in the dataset).  \n",
    "Or rows with missing values may be unique in some other way.  \n",
    "In that case, your model would make better predictions by considering which values were originally missing.  \n",
    "Here's how it might look:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make a copy to keep the original data intact:\n",
    "new_data = original_data.copy()\n",
    "\n",
    "# Make new columns indicating what will be imputed:\n",
    "cols_with_missing = [col for col in new_data.columns\n",
    "                                 if new_data[c].isnull().any()]\n",
    "# Compare and contrast:\n",
    "for col in cols_with_missing:\n",
    "    new_data[col + ' was missing'] = new_data[col].isnull()\n",
    "    \n",
    "# Impute:\n",
    "my_imputer = Imputer()\n",
    "new_data = my_imputer.fit_transform(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach may or may not improve the results compared to simply imputing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example comparing the solutions using the Melbourne Housing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see an example predicting housing prices from the Melbourne Housing data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mb_data = pd.read_csv('input/melbourne_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mb_target = mb_data.Price\n",
    "mb_predictors = mb_data.drop(['Price'], axis=1)\n",
    "\n",
    "# In order to simplify this example, only numeric predictors are used.\n",
    "mb_numeric_predictors = mb_predictors.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to measure how well each approach performs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide our data into training and test.  \n",
    "We've loaded a function `score_dataset(X_train, X_test, y_train, y_test)` to compare the quality of different approaches to missing values.  \n",
    "This function reports the out-of-sample MAE score from a RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mb_numeric_predictors, mb_target, train_size=0.7,\n",
    "                                                   test_size=0.3, random_state=0)\n",
    "\n",
    "def score_dataset(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mae(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error after dropping columns with missing values:\n",
      "347575.785631455\n"
     ]
    }
   ],
   "source": [
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_test = X_test.drop(cols_with_missing, axis=1)\n",
    "print(\"Mean Absolute Error after dropping columns with missing values:\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model score from imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error after imputing misssing values:\n",
      "204966.73475267258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "print(\"Mean Absolute Error after imputing misssing values:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get score after imputation and display imputed values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error while tracking imputed values:\n",
      "201584.8448994383\n"
     ]
    }
   ],
   "source": [
    "imputed_X_train_plus = X_train.copy()\n",
    "imputed_X_test_plus = X_test.copy()\n",
    "\n",
    "# https://www.python.org/dev/peps/pep-0289/\n",
    "cols_with_missing = (col for col in X_train.columns if X_train[col].isnull().any())\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    imputed_X_train_plus[col + ' was missing'] = imputed_X_train_plus[col].isnull()\n",
    "    imputed_X_test_plus[col + ' was missing'] = imputed_X_test_plus[col].isnull()\n",
    "    \n",
    "# Imputation\n",
    "my_imputer = Imputer()\n",
    "imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\n",
    "imputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n",
    "\n",
    "print(\"Mean Absolute Error while tracking imputed values:\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between imputation and imputation with extension is trivial compared to dropping entire columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Categorical Data and One-Hot Encoding](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
