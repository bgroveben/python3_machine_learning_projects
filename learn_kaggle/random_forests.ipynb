{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Random Forests](https://www.kaggle.com/dansbecker/random-forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees leave you with a difficult decision.  \n",
    "A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf.  \n",
    "But a shallow tree with few leaves will perform poorly because it fails to capture as many distinctions in the raw data.  \n",
    "Even today's most sophisticated modeling techniques face this tension between underfitting and overfitting.  \n",
    "But, many models have clever ideas that can lead to better performance.  \n",
    "We'll look at the random forest as an example.  \n",
    "The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree.  \n",
    "It generally has much better predictive accuracy than a single decision tree and it works well with the default parameters.  \n",
    "If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'input/melbourne_data.csv'\n",
    "mb_data = pd.read_csv(file_path)\n",
    "mb_data = mb_data.dropna(axis=0)\n",
    "y = mb_data.Price\n",
    "mb_predictors = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = mb_data[mb_predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `RandomForest` is built in much the same way that a decision tree is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203752.1210673553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_model.fit(train_X, train_y)\n",
    "melbourne_predictions = forest_model.predict(val_X)\n",
    "print(mae(val_y, melbourne_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is likely room for further improvement, but this is a big improvement over the best decision tree error of 250,000.  \n",
    "There are parameters which allow you to change the performance of the Random Forest much as we changed the maximum depth of the single decision tree.  \n",
    "But one of the best features of Random Forest models is that they generally work reasonably even without this tuning.  \n",
    "You'll soon learn the XGBoost model, which provides better performance when tuned well with the right parameters (but which requires some skill to get the right settings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Submitting From A Kernel](https://www.kaggle.com/dansbecker/submitting-from-a-kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning competitions are a great way to improve your skills and measure your progress as a data scientist.  \n",
    "If you are using data from a competition on Kaggle, you can easily submit it from your notebook.  \n",
    "We're doing very minimal data set up here so we can focus on how to submit modeling results to competitions.  \n",
    "Other tutorials will teach you how to build great models.  \n",
    "So the model in this example will be fairly simple.  \n",
    "We'll start with the sample code to read data, select predictors, and fit a model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Read the data:\n",
    "train = pd.read_csv('input/train.csv')\n",
    "\n",
    "# Set the target and predictors:\n",
    "train_y = train.SalePrice\n",
    "predictor_cols = ['LotArea', 'OverallQual', 'YearBuilt', 'TotRmsAbvGrd']\n",
    "\n",
    "# Create training predictors data:\n",
    "train_x = train[predictor_cols]\n",
    "\n",
    "da_model = RandomForestRegressor()\n",
    "da_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to your training data, there will be test data.  \n",
    "This is frequently stored in a file with the title test.csv.  \n",
    "This data won't include a column with your target (y), because that is what we'll have to predict and submit.  \n",
    "Here is the sample code to do that."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test = pd.read_csv('input/test.csv')\n",
    "test_X = test[predictor_cols]\n",
    "predicted_prices = my_model.predict(test_X)\n",
    "print(predicted_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make submissions in CSV files.  \n",
    "Your submissions usually have two columns: an ID column and a prediction column.  \n",
    "The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the housing data is the string 'Id').  \n",
    "The prediction column will use the name of the target field.  \n",
    "We will create a DataFrame with this data, and then use the dataframe's `to_csv` method to write our submission file.  \n",
    "Explicitly include the argument `index=False` to prevent pandas from adding another column in our csv file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "da_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n",
    "da_submission.to_csv('somefile.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit the blue **Publish** button at the top of your notebook screen.  \n",
    "It will take some time for your kernel to run.  \n",
    "When it has finished your navigation bar at the top of the screen will have a tab for Output.  \n",
    "This only shows up if you have written an output file (like we did in the Prepare Submission File step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
