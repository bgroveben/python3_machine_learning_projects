{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks for Beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an artificial neural network that learns to generate handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By [Jon Bruner](https://github.com/jonbruner) and [Adit Deshpande](https://github.com/adeshpande3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a GAN that will generate handwritten digits that can fool even the best classifiers (and humans as well).  \n",
    "We'll use [TensorFlow](https://www.tensorflow.org/), a deep learing library open-sourced by Google that makes it easy to train neural networks on GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a set of real handwritten digits to give the discriminator a starting point in distinguishing between real and fake images.  \n",
    "In this tutorial, we are going to use [MNIST](http://yann.lecun.com/exdb/mnist/), a benchmark dataset in deep learning.  \n",
    "Let us begin by importing TensorFlow along with a couple of other helpful libraries.  \n",
    "We'll also import our MNIST images using a TensorFlow convenience function called `read_data_sets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST variable we created above contains both the images and their labels, divided into a training set called `train` and a validation set called `validation`.  \n",
    "We can retrieve batches of images by calling `next_batch` on `mnist`.  \n",
    "Let's load up an image and have a look, shall we?  \n",
    "The images are initially formatted as a single row of 784 pixels.  \n",
    "We can reshape them into 28 x 28-pixel images and view them using PyPlot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x125323c88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvOBZxaUt9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c46d668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the cell above again, you'll see a different image form the MNIST training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our discriminator is a convolutional neural network that takes in an image of size 28 x 28 x 1 as input and returns a single scalar number that describes whether or not the input image is \"real\" or \"fake\" -- that is, whether it's drawn from the set of MNIST images or generated by the generator.  \n",
    "The structure of the discriminator network features two convolutional layers that find 5 x 5 pixel features, and two \"fully connected\" layers that multiply weights by every pixel in the image.  \n",
    "To set up each layer, we start by creating weight and bias variables through `tf.get_variable`.  \n",
    "Weights are initialized from a [truncated normal distribution](https://www.tensorflow.org/api_docs/python/tf/truncated_normal), and biases are initialized at zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.conv2d()` is TensorFlow's standard convolution function.  \n",
    "It takes 4 arguments.  \n",
    "The first is the input volume (our `28 x 28 x 1` images in this case).  \n",
    "The next argument is the filter/weight matrix.  \n",
    "Finally, you can also change the stride and padding of the convolution.  \n",
    "those two values affect the dimensions of the output volume.  \n",
    "If you're already comfortable with CNNs, you'll recognize this as a simple binary classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    if (reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "    # First convolutional and pool layers.\n",
    "    # This finds 32 different 5 x 5 pixel features:\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b1 = tf.get_variable('d_b1', [32],\n",
    "                          initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    # Second convolutional and pool layers.\n",
    "    # This finds 64 different 5 x 5 pixel features:\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64],\n",
    "                          initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    # First fully connected layer:\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024],\n",
    "                          initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "    \n",
    "    # Second fully connected layer:\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1],\n",
    "                          initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "    \n",
    "    # d4 contains unscaled values:\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our discriminator defined, let's take a look at the generator model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll base the overall structure of our model on a simple generator [published by Tim O'Shea](https://github.com/osh/KerasGAN).  \n",
    "You can think of a generator as a kind of reverse convolutional neural network.  \n",
    "A typical CNN like our discriminator network transforms a 2- or 3-dimensional matrix of pixel values into a single probability.  \n",
    "A generator, however, takes a `d`-dimensional vector of noise and upsamples it to become a 28 x 28 image.  \n",
    "[ReLU](https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29) and [batch normalization](https://arxiv.org/abs/1502.03167) are used to stabilize the outputs of each layer.  \n",
    "In our generator network, we use three convolutional layers along with interpolation until a `28 x 28` pixel image is formed.  \n",
    "Actually, as you'll see below, we've taken care to form `28 x 28 x 1` images; many TensorFlow tools for dealing with images anticipate that the images will have some number of *channels* -- usually 1 for grayscale images or 3 for RGB color images.  \n",
    "At the output layer, we add a `tf.sigmoid()` activation function; this squeezes pixels that would appear gray toward either black or white, resulting in a crisper image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z is a tensor of random values, z_dim is the number of random values fed in for each image being produced.\n",
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "    \n",
    "    # Generate 50 features:\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "    \n",
    "    # Generate 25 features:\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "    \n",
    "    # Final convolution with one output channel:\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Sample Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have defined both the generator and discriminator functions.  \n",
    "Let's see what a sample output from an untrained generator looks like.  \n",
    "We need to open a TensorFlow session and create a placeholder for the input to our generator.  \n",
    "The shape of the placeholder will be `None x z_dimensions`.  \n",
    "The `None` keyword means that the value can be determined at session runtime.  \n",
    "We normally have `None` as our first dimension so that we can have variable batch sizes.  \n",
    "For example, with a batch size of 50, the input to the generator would be 50 x 100.  \n",
    "With the `None` keyword, we don't have to specify `batch_size` until later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a variable (`generated_image_output`) that holds the output of the generator, and we'll also initialize the random noise vector that we're going to use as input.  \n",
    "The `np.random_normal()` function has three arguments.  \n",
    "The first and second define the mean and standard deviation for the normal distribution (0 and 1 in our case), and the third defines the shape of the vector (`1 x 100`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize all of the variables, feed our `z_batch` into the placeholder, and run the session.  \n",
    "The `sess.run()` function has two arguments.  \n",
    "The first is called the \"fetches\" argument; it defines the value you're interested in computing.  \n",
    "In our case, we want to see what the output of the generator is.  \n",
    "If you look back at the last code snippet, you'll see that the output of the generator function is stored in `generated_image_output`, so we'll use `generated_image_output` for our first argument.  \n",
    "The second argument takes a dictionary of inputs that are substituted into the graph when it runs.  \n",
    "This is where we feed in our placeholders.  \n",
    "In our example, we need to feed our `z_batch` variable into the `z_placeholder` that we defined earlier.  \n",
    "As before, we'll view the image by reshaping it to `28 x 28` pixels and show it with PyPlot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1190e72e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output,\n",
    "                              feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28, 28])\n",
    "    plt.imshow(generated_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have an image of randomly generated noise.  \n",
    "Now we need to train the weights and biases in the generator network to convert random numbers into recognizable digits.  \n",
    "Time to take a look at loss functions and optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
