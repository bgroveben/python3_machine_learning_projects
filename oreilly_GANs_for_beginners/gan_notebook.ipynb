{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks for Beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an artificial neural network that learns to generate handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By [Jon Bruner](https://github.com/jonbruner) and [Adit Deshpande](https://github.com/adeshpande3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a GAN that will generate handwritten digits that can fool even the best classifiers (and humans as well).  \n",
    "We'll use [TensorFlow](https://www.tensorflow.org/), a deep learing library open-sourced by Google that makes it easy to train neural networks on GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a set of real handwritten digits to give the discriminator a starting point in distinguishing between real and fake images.  \n",
    "In this tutorial, we are going to use [MNIST](http://yann.lecun.com/exdb/mnist/), a benchmark dataset in deep learning.  \n",
    "Let us begin by importing TensorFlow along with a couple of other helpful libraries.  \n",
    "We'll also import our MNIST images using a TensorFlow convenience function called `read_data_sets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST variable we created above contains both the images and their labels, divided into a training set called `train` and a validation set called `validation`.  \n",
    "We can retrieve batches of images by calling `next_batch` on `mnist`.  \n",
    "Let's load up an image and have a look, shall we?  \n",
    "The images are initially formatted as a single row of 784 pixels.  \n",
    "We can reshape them into 28 x 28-pixel images and view them using pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1226e00f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADoxJREFUeJzt3W2MVHWWx/HfAQWFGR+QXiSINjsha4xxGVMRE0TdzAJi\nJmnQoEPiyCZkGRONSzIvVl1xTXwhGmZwEpUIiAMbdGYMGEkky7hkfZhECKVhfcB1fWoVRGh04sgL\nReHsi75MWun6V3XVrXurPd9P0umqe+6te7j0r2/V/VfX39xdAOIZUXYDAMpB+IGgCD8QFOEHgiL8\nQFCEHwiK8ANBEX4gKMIPBHVSkTsbP368d3d3F7lLIJTe3l4dOnTIGlm3pfCb2VWSfiNppKS17r48\ntX53d7eq1WoruwSQUKlUGl636af9ZjZS0kOS5kq6QNJCM7ug2ccDUKxWXvNfIukdd3/P3Y9I+p2k\nnnzaAtBurYR/kqSPBtzfmy37FjNbYmZVM6v29fW1sDsAeWr71X53X+3uFXevdHV1tXt3ABrUSvj3\nSZo84P452TIAw0Ar4d8laaqZTTGzUZJ+JmlLPm0BaLemh/rc/Rszu0XSNvUP9a1z9zdy6wxAW7U0\nzu/uWyVtzakXAAXi7b1AUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8E1dIsvWbWK+kLSUclfePulTyawrd99NFHyfr7779fUCcnmjx5crI+ZcqUgjrBULUU/sw/uPuh\nHB4HQIF42g8E1Wr4XdIfzexlM1uSR0MAitHq0/7L3H2fmf2NpGfN7H/d/YWBK2S/FJZI0rnnntvi\n7gDkpaUzv7vvy74flPSUpEsGWWe1u1fcvdLV1dXK7gDkqOnwm9lYM/vh8duSZkt6Pa/GALRXK0/7\nJ0h6ysyOP87j7v6fuXQFoO2aDr+7vyfp73PsZdg6duxYsn7kyJFk/dCh9EjpnDlzkvW33norWW+n\n7u7uZH3GjBnFNDKIlStX1qydfvrpyW1POimPUfDOxlAfEBThB4Ii/EBQhB8IivADQRF+IKjv/3hG\nAbZu3Zqs9/T0FNRJ8Xp7e1uqt9PGjRtr1jZv3pzc9vv8f3YcZ34gKMIPBEX4gaAIPxAU4QeCIvxA\nUIQfCIpx/sxXX32VrM+fP79m7aWXXsq7HbTZ7bffnqxPnz49WR83blyyPmrUqCH3VDTO/EBQhB8I\nivADQRF+ICjCDwRF+IGgCD8QFOP8mRdffDFZ37ZtW0GdoAj1Pu580qRJyfpzzz2XrM+cOXOoLRWO\nMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFV3nN/M1kn6qaSD7n5htmycpN9L6pbUK+k6d/9z+9ps\n3aZNm5L1xYsXF9TJ0J133nnJ+rx582rW6v3dej0PPPBAsr58+fKWHj+l3r/7xhtvTNbvv//+mrV6\nn98QQSNn/t9Kuuo7y26TtN3dp0rant0HMIzUDb+7vyDps+8s7pG0Pru9XlLtUw+AjtTsa/4J7r4/\nu/2JpAk59QOgIC1f8HN3l+S16ma2xMyqZlbt6+trdXcActJs+A+Y2URJyr4frLWiu69294q7V7q6\nuprcHYC8NRv+LZIWZbcXSXo6n3YAFKVu+M3sCUkvSfo7M9trZoslLZc0y8zelvSP2X0Aw0jdcX53\nX1ij9JOce2mrBQsWJOtmVlAnJ6o3nv38888n65MnT86znW+55557kvXPP/88WV+1alXT+/7ggw+S\n9Xr/7vvuu69mbenSpU31dNzatWuTdf6eH0DHIvxAUIQfCIrwA0ERfiAowg8EZf3vzi1GpVLxarVa\n2P4GGjEi/XuulaG+MWPGJOvr169P1ufOnZusn3rqqUPuqSi7d+9O1ufMmVOzdujQoeS2F110UbK+\nc+fOZH3v3r01a1OnTk1u26qjR4+29fFrqVQqqlarDf0wc+YHgiL8QFCEHwiK8ANBEX4gKMIPBEX4\ngaDCTNFd7/0MrYzzP/jgg8n6Nddc0/Rjd7pp06Yl66mPTL/iiiuS26bG6SVp2bJlyfr111+frEfH\nmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHggozzt/Oj+a+/PLL2/bYw12lUqlZu/TSS5Pb7tixI1lf\nsWJFsr5nz55kPTrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVN1xfjNbJ+mnkg66+4XZsrsl/bOk\nvmy1O9x9a7uaxPB1yimn1Kxt2bIlue27777b0r5Hjx5ds7Z1Kz+ujZz5fyvpqkGWr3T3adkXRxIY\nZuqG391fkPRZAb0AKFArr/lvMbNXzWydmZ2ZW0cACtFs+FdJ+pGkaZL2S/pVrRXNbImZVc2s2tfX\nV2s1AAVrKvzufsDdj7r7MUlrJF2SWHe1u1fcvdLV1dVsnwBy1lT4zWzigLvzJb2eTzsAitLIUN8T\nkq6UNN7M9kr6d0lXmtk0SS6pV9Iv2tgjgDaoG353XzjI4kfb0AuCOeuss1qqf/jhh8n69OnTh9xT\no74PczHwDj8gKMIPBEX4gaAIPxAU4QeCIvxAUGE+urud7rrrrmR97dq1yXrqT08j+/jjj5P1WbNm\nJesHDx7Ms51vufXWW9v22EXhzA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQYUZ57/hhhuS9Y0bNzb9\n2I8//niy/vXXXyfrN910U7J+5ZVXDrWljnHkyJGatSeffDK57Z133pms1/uT3lacf/75yfqUKVPa\ntu+icOYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaDCjPM/8sgjyfppp52WrK9atarpfdcbz37mmWeS\n9YsvvjhZf+yxx2rWxo4dm9y2VTt27EjW77333pq1Xbt25d1Ow84555xkffv27cn62WefnWc7peDM\nDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBmbunVzCbLGmDpAmSXNJqd/+NmY2T9HtJ3ZJ6JV3n7n9O\nPValUvFqtZpD2/n78ssvk/V2j5ejWJs3b07We3p6CuokX5VKRdVq1RpZt5Ez/zeSfunuF0i6VNLN\nZnaBpNskbXf3qZK2Z/cBDBN1w+/u+939lez2F5LelDRJUo+k9dlq6yXNa1eTAPI3pNf8ZtYt6ceS\ndkqa4O77s9In6n9ZAGCYaDj8ZvYDSZskLXX3vwysef+Fg0EvHpjZEjOrmlm1r6+vpWYB5Keh8JvZ\nyeoP/kZ3P36l5ICZTczqEyUNOiuiu69294q7V7q6uvLoGUAO6obfzEzSo5LedPdfDyhtkbQou71I\n0tP5twegXRr5k94Zkn4u6TUz250tu0PSckl/MLPFkj6QdF17WizGqFGjkvVPP/20Zm3ZsmXJbR9+\n+OGmeopuzJgxyXq9jzR/6KGHatYmTOASVd3wu/ufJNUaN/xJvu0AKArv8AOCIvxAUIQfCIrwA0ER\nfiAowg8EFeaju+sZMSL9e/CMM86oWVuxYkVy28OHDyfrGzZsSNa/rxYsWJCs33zzzcn6zJkz82wn\nHM78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/w5GD16dLK+Zs2aZL3e9N/btm1L1ut9DHU7zZ49\nO1m/9tpra9ZGjhyZ3Pbkk09uqic0hjM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH8BTjopfZjr\n1etNFz1cp5NGuTjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQdcNvZpPN7L/NbI+ZvWFm/5Itv9vM\n9pnZ7uzr6va3CyAvjbzJ5xtJv3T3V8zsh5JeNrNns9pKd0/PWAGgI9UNv7vvl7Q/u/2Fmb0paVK7\nGwPQXkN6zW9m3ZJ+LGlntugWM3vVzNaZ2Zk1tlliZlUzq/b19bXULID8NBx+M/uBpE2Slrr7XySt\nkvQjSdPU/8zgV4Nt5+6r3b3i7pWurq4cWgaQh4bCb2Ynqz/4G919syS5+wF3P+ruxyStkXRJ+9oE\nkLdGrvabpEclvenuvx6wfOKA1eZLej3/9gC0SyNX+2dI+rmk18xsd7bsDkkLzWyaJJfUK+kXbekQ\nQFs0crX/T5JskNLW/NsBUBTe4QcERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwjK3L24nZn1SfpgwKLxkg4V1sDQdGpvndqXRG/NyrO389y9oc/LKzT8J+zcrOru\nldIaSOjU3jq1L4nemlVWbzztB4Ii/EBQZYd/dcn7T+nU3jq1L4nemlVKb6W+5gdQnrLP/ABKUkr4\nzewqM3vLzN4xs9vK6KEWM+s1s9eymYerJfeyzswOmtnrA5aNM7Nnzezt7Pug06SV1FtHzNycmFm6\n1GPXaTNeF/6038xGSvo/SbMk7ZW0S9JCd99TaCM1mFmvpIq7lz4mbGaXSzosaYO7X5gtu1/SZ+6+\nPPvFeaa7/2uH9Ha3pMNlz9ycTSgzceDM0pLmSfonlXjsEn1dpxKOWxln/kskvePu77n7EUm/k9RT\nQh8dz91fkPTZdxb3SFqf3V6v/h+ewtXorSO4+353fyW7/YWk4zNLl3rsEn2VoozwT5L00YD7e9VZ\nU367pD+a2ctmtqTsZgYxIZs2XZI+kTShzGYGUXfm5iJ9Z2bpjjl2zcx4nTcu+J3oMne/WNJcSTdn\nT287kve/Zuuk4ZqGZm4uyiAzS/9Vmceu2Rmv81ZG+PdJmjzg/jnZso7g7vuy7wclPaXOm334wPFJ\nUrPvB0vu5686aebmwWaWVgccu06a8bqM8O+SNNXMppjZKEk/k7SlhD5OYGZjswsxMrOxkmar82Yf\n3iJpUXZ7kaSnS+zlWzpl5uZaM0ur5GPXcTNeu3vhX5KuVv8V/3cl/VsZPdTo628l/U/29UbZvUl6\nQv1PA79W/7WRxZLOkrRd0tuS/kvSuA7q7T8kvSbpVfUHbWJJvV2m/qf0r0ranX1dXfaxS/RVynHj\nHX5AUFzwA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1P8D8MdeQgM+SS8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e8639b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the cell above again, you'll see a different image form the MNIST training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our discriminator is a convolutional neural network that takes in an image of size 28 x 28 x 1 as input and returns a single scalar number that describes whether or not the input image is \"real\" or \"fake\" -- that is, whether it's drawn from the set of MNIST images or generated by the generator.  \n",
    "The structure of the discriminator network features two convolutional layers that find 5 x 5 pixel features, and two \"fully connected\" layers that multiply weights by every pixel in the image.  \n",
    "To set up each layer, we start by creating weight and bias variables through `tf.get_variable`.  \n",
    "Weights are initialized from a [truncated normal distribution](https://www.tensorflow.org/api_docs/python/tf/truncated_normal), and biases are initialized at zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.conv2d()` is TensorFlow's standard convolution function.  \n",
    "It takes 4 arguments.  \n",
    "The first is the input volume (our `28 x 28 x 1` images in this case).  \n",
    "The next argument is the filter/weight matrix.  \n",
    "Finally, you can also change the stride and padding of the convolution.  \n",
    "those two values affect the dimensions of the output volume.  \n",
    "If you're already comfortable with CNNs, you'll recognize this as a simple binary classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    if (reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "    # First convolutional and pool layers.\n",
    "    # This finds 32 different 5 x 5 pixel features:\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b1 = tf.get_variable('d_b1', [32],\n",
    "                          initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    # Second convolutional and pool layers.\n",
    "    # This finds 64 different 5 x 5 pixel features:\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64],\n",
    "                          initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    # First fully connected layer:\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024],\n",
    "                          initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "    \n",
    "    # Second fully connected layer:\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1],\n",
    "                          initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "    \n",
    "    # d4 contains unscaled values:\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our discriminator defined, let's take a look at the generator model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll base the overall structure of our model on a simple generator [published by Tim O'Shea](https://github.com/osh/KerasGAN).  \n",
    "You can think of a generator as a kind of reverse convolutional neural network.  \n",
    "A typical CNN like our discriminator network transforms a 2- or 3-dimensional matrix of pixel values into a single probability.  \n",
    "A generator, however, takes a `d`-dimensional vector of noise and upsamples it to become a 28 x 28 image.  \n",
    "[ReLU](https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29) and [batch normalization](https://arxiv.org/abs/1502.03167) are used to stabilize the outputs of each layer.  \n",
    "In our generator network, we use three convolutional layers along with interpolation until a `28 x 28` pixel image is formed.  \n",
    "Actually, as you'll see below, we've taken care to form `28 x 28 x 1` images; many TensorFlow tools for dealing with images anticipate that the images will have some number of *channels* -- usually 1 for grayscale images or 3 for RGB color images.  \n",
    "At the output layer, we add a `tf.sigmoid()` activation function; this squeezes pixels that would appear gray toward either black or white, resulting in a crisper image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z is a tensor of random values, z_dim is the number of random values fed in for each image being produced.\n",
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "    \n",
    "    # Generate 50 features:\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "    \n",
    "    # Generate 25 features:\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "    \n",
    "    # Final convolution with one output channel:\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1],\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
