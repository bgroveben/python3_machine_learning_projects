{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How to Prepare Text Data for Machine Learning with scikit-learn](https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/)  \n",
    "\n",
    "## by Jason Brownlee on September 29, 2017 in Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text data requires special preparation before you can start using it for predictive modeling.  \n",
    "The text must be parsed to remove words, called tokenization.  \n",
    "Then the words need to be encoded as integers or floating point values for use as input to a machine learning algorithm, called feature extraction (or vectorization).  \n",
    "The scikit-learn library offers easy-to-use tools to perform both tokenization and feature extraction of your text data.  \n",
    "In this tutorial, you will discover exactly how you can prepare your text data for predictive modeling in Python with scikit-learn.  \n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "- How to convert text to word count vectors with CountVectorizer.\n",
    "- How to convert text to word frequency vectors with TfidfVectorizer.\n",
    "- How to convert text to unique integers with HashingVectorizer.  \n",
    "\n",
    "Letâ€™s get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
